{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## MED 4 \n",
    "\n",
    "# Regresja wieloraka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prognozowanie cen domów (wiele zmiennych)\n",
    "\n",
    "W tym notatniku wykorzystamy dane dotyczące sprzedaży domów. Przewidywanie ich ceny zostanie dokonane przy pomocy regresji wielorakiej. Pierwsze zadanie dotyczy eksploracji regresji wielorakiej poprzez opracowanie nowych cech i pomiar błędu. W drugim zadaniu zaimplementować należy algorytm spadku gradientu.\n",
    "\n",
    "     Użyj wbudowanych funkcji tworzenia wykresów (lub w inny sposób), aby obliczyć wagi regresji (współczynniki)\n",
    "     Biorąc pod uwagę wagi regresji, predyktory i wynik napisz funkcję obliczającą resztkową sumę kwadratów.\n",
    "     Spójrz na współczynniki i zinterpretuj ich znaczenie.\n",
    "     Oceń wiele modeli za pomocą RSS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potrzebne biblioteki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wczytanie danych ceny domów \n",
    "\n",
    "Zestaw danych pochodzi ze sprzedaży domów w King County, regionie, w którym znajduje się miasto Seattle w stanie Waszyngton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, 'grade':int, 'yr_renovated':int, 'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, 'sqft_lot15':float, 'sqft_living':float, 'floors':str, 'condition':int, 'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}\n",
    "domy = pd.read_csv('kc_house_data.csv',sep=',', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>5650</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>5650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>7242</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690.0</td>\n",
       "      <td>7639.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>8062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>8080</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>7503.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0       3.0       1.00       1180.0   \n",
       "1  6414100192  20141209T000000  538000.0       3.0       2.25       2570.0   \n",
       "2  5631500400  20150225T000000  180000.0       2.0       1.00        770.0   \n",
       "3  2487200875  20141209T000000  604000.0       4.0       3.00       1960.0   \n",
       "4  1954400510  20150218T000000  510000.0       3.0       2.00       1680.0   \n",
       "\n",
       "   sqft_lot floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650      1           0     0  ...      7        1180              0   \n",
       "1      7242      2           0     0  ...      7        2170            400   \n",
       "2     10000      1           0     0  ...      6         770              0   \n",
       "3      5000      1           0     0  ...      7        1050            910   \n",
       "4      8080      1           0     0  ...      8        1680              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257         1340.0   \n",
       "1      1951          1991    98125  47.7210 -122.319         1690.0   \n",
       "2      1933             0    98028  47.7379 -122.233         2720.0   \n",
       "3      1965             0    98136  47.5208 -122.393         1360.0   \n",
       "4      1987             0    98074  47.6168 -122.045         1800.0   \n",
       "\n",
       "   sqft_lot15  \n",
       "0      5650.0  \n",
       "1      7639.0  \n",
       "2      8062.0  \n",
       "3      5000.0  \n",
       "4      7503.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domy.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "domy.bathrooms.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Podziel dane na uczące i testowe.\n",
    "Używamy seed = 0, aby każdy, kto korzysta z tego notebooka, uzyskał te same wyniki. W praktyce możesz ustawić podział losowy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'date', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot',\n",
       "       'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n",
       "       'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat',\n",
       "       'long', 'sqft_living15', 'sqft_lot15'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = domy['price']\n",
    "X = domy.drop(['price'], axis=1)\n",
    "features = X.columns.values\n",
    "features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nauka modelu regresji wielorakiej"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykorzystując cechy 'sqft_living', 'bedrooms', 'bathrooms' uczymy nasz model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_features = ['sqft_living', 'bedrooms', 'bathrooms']\n",
    "pinw = np.linalg.pinv(X_train[example_features])\n",
    "w = np.dot(pinw,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po dopasowaniu modelu możemy wyodrębnić współczynniki (wagi) modelu regresji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Otrzymane współczynniki: [   308.54966331 -41754.38204544  17354.12106635]\n"
     ]
    }
   ],
   "source": [
    "print('Otrzymane współczynniki:', w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przewidywanie wartości modelu\n",
    "\n",
    "Mając wyliczone parametry modelu napisz funkcję do przewidywania wartości dla zadanego modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 383748.43603868 1330310.29293091  373818.34187199 ...  337749.69862805\n",
      "  185213.15507236  419805.07408762]\n"
     ]
    }
   ],
   "source": [
    "def predict_output(params, features):\n",
    "    return np.dot(features, params)\n",
    "df = X_test[example_features]\n",
    "predictions = predict_output(w, df)\n",
    "\n",
    "print(predictions)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wyliczamy błąd (SSE -  sum of squared estimate of errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz, gdy możemy wykonać przewidywania na podstawie modelu, napiszmy funkcję obliczającą RSS modelu. Wykonaj poniższą funkcję, aby obliczy sumę kwadratów błędu estymacji (SSE) na podstawie modelu, danych i wyniku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policz_SSE(model, data, outcome):\n",
    "    predictions = predict_output(model, data)\n",
    "    err = np.abs(outcome-predictions)\n",
    "    SSE = 0\n",
    "    for i in err:\n",
    "        SSE+=i*i\n",
    "\n",
    "    return(SSE)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przetestuj swoją funkcję obliczając błąd SSE z danych TEST dla przykładowego modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261738485259246.44\n"
     ]
    }
   ],
   "source": [
    "przykladowe_rss = policz_SSE(w, X_test[example_features], y_test)\n",
    "print(przykladowe_rss) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utwórz nowe cechy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mimo iż nasz model regresji wielorakiej obejmuje wiele różnych cech (np. ilosc_sypiani, powierzchnia i ilosc_lazienek) możemy również rozważyć przekształcenie istniejących cech, np. log(powierzchnia) czy nawet mnożenie ilości sypialni i łazienek."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Użyjemy funkcji logarytmu, aby utworzyć nowe cechy, więc najpierw importujemy ją z biblioteki matematycznej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Następnie utwórz następujące 4 nowe cechy jako kolumny w danych TRENINGOWYCH i TESTOWYCH:\n",
    "* bedrooms_squared = bedrooms\\*bedrooms\n",
    "* bed_bath_rooms = bedrooms\\*bathrooms\n",
    "* log_sqft_living = log(sqft_living)\n",
    "* lat_plus_long = lat + long \n",
    "\n",
    "Jako przykład oto pierwsza:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['bedrooms_squared'] = X_train['bedrooms'].apply(lambda x: x**2)\n",
    "X_test['bedrooms_squared'] = X_test['bedrooms'].apply(lambda x: x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               id             date  bedrooms  bathrooms  sqft_living  \\\n",
      "17384  1453602313  20141029T000000       2.0       1.50       1430.0   \n",
      "722    2225059214  20140808T000000       4.0       3.25       4670.0   \n",
      "2680   2768000270  20140625T000000       2.0       0.75       1440.0   \n",
      "18754  6819100040  20140624T000000       2.0       1.00       1130.0   \n",
      "14554  4027700666  20150426T000000       4.0       2.50       3180.0   \n",
      "...           ...              ...       ...        ...          ...   \n",
      "5427   3528000545  20140815T000000       4.0       3.25       3090.0   \n",
      "16547  0526059259  20140819T000000       3.0       1.75       1260.0   \n",
      "4585   0339600090  20140925T000000       3.0       2.50       1360.0   \n",
      "17762  7750500120  20141118T000000       3.0       1.00        950.0   \n",
      "16323  0267000170  20141210T000000       3.0       2.25       1640.0   \n",
      "\n",
      "       sqft_lot floors  waterfront  view  condition  ...  yr_renovated  \\\n",
      "17384      1650      3           0     0          3  ...             0   \n",
      "722       51836      2           0     0          4  ...             0   \n",
      "2680       3700      1           0     0          3  ...             0   \n",
      "18754      2640      1           0     0          4  ...             0   \n",
      "14554      9603      2           0     2          3  ...             0   \n",
      "...         ...    ...         ...   ...        ...  ...           ...   \n",
      "5427      67518      2           0     0          3  ...             0   \n",
      "16547      8487      1           0     0          3  ...             0   \n",
      "4585       3718      2           0     0          3  ...             0   \n",
      "17762      4760    1.5           0     0          3  ...             0   \n",
      "16323     12000      1           0     0          3  ...             0   \n",
      "\n",
      "       zipcode      lat     long  sqft_living15 sqft_lot15  bedrooms_squared  \\\n",
      "17384    98125  47.7222 -122.290         1430.0     1650.0               4.0   \n",
      "722      98005  47.6350 -122.164         4230.0    41075.0              16.0   \n",
      "2680     98107  47.6707 -122.364         1440.0     4300.0               4.0   \n",
      "18754    98109  47.6438 -122.357         1680.0     3200.0               4.0   \n",
      "14554    98155  47.7717 -122.277         2440.0    15261.0              16.0   \n",
      "...        ...      ...      ...            ...        ...               ...   \n",
      "5427     98053  47.6674 -122.046         3200.0    65775.0              16.0   \n",
      "16547    98011  47.7664 -122.201         1890.0    13051.0               9.0   \n",
      "4585     98052  47.6827 -122.097         1090.0     3718.0               9.0   \n",
      "17762    98106  47.5236 -122.348         1080.0     4760.0               9.0   \n",
      "16323    98008  47.6252 -122.104         1620.0    12000.0               9.0   \n",
      "\n",
      "       bed_bath_rooms  log_sqft_living  lat_plus_long  \n",
      "17384            3.00         7.265430       -74.5678  \n",
      "722             13.00         8.448914       -74.5290  \n",
      "2680             1.50         7.272398       -74.6933  \n",
      "18754            2.00         7.029973       -74.7132  \n",
      "14554           10.00         8.064636       -74.5053  \n",
      "...               ...              ...            ...  \n",
      "5427            13.00         8.035926       -74.3786  \n",
      "16547            5.25         7.138867       -74.4346  \n",
      "4585             7.50         7.215240       -74.4143  \n",
      "17762            3.00         6.856462       -74.8244  \n",
      "16323            6.75         7.402452       -74.4788  \n",
      "\n",
      "[4323 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# utwórz pozostałe 3 funkcje zarówno w danych TRENINGOWYCH, jak i TESTOWYCH\n",
    "X_train['bed_bath_rooms'] = X_train['bedrooms']* X_train['bathrooms']\n",
    "X_test['bed_bath_rooms'] = X_test['bedrooms']* X_test['bathrooms']\n",
    "X_train['log_sqft_living'] = X_train['sqft_living'].apply(lambda x: log(x))\n",
    "X_test['log_sqft_living'] = X_test['sqft_living'].apply(lambda x: log(x))\n",
    "X_train['lat_plus_long'] = X_train['lat']+X_train['long']\n",
    "X_test['lat_plus_long'] = X_test['lat']+ X_test['long']\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Kwadrat sypialni zwiększa separację między nielicznymi sypialniami (np. 1) i wieloma sypialniami (np. 4), ponieważ 1 ^ 2 = 1, ale 4 ^ 2 = 16. W konsekwencji ta funkcja będzie miała wpływ głównie na domy z wieloma sypialniami.\n",
    "* Sypialnia razy łazienka daje tak zwaną funkcję „interakcji”. Wynik jest wysoki, gdy  wartościu *obu* cech są duże.\n",
    "* Przejęcie logarytmu stóp kwadratowych powoduje zbliżenie dużych wartości i rozłożenie małych wartości. Wynika to z reguły prawoskośności posiadanych danych/posiadanego atrybutu.\n",
    "* Dodawanie szerokości do długości geograficznej jest całkowicie bezsensowne, ale i tak to zrobimy (zobaczymy później dlaczego)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pytanie quizu: Jaka jest średnia (średnia arytmetyczna) twoich 4 nowych funkcji w danych TEST? (w zaokrągleniu do 2 cyfr)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.21\n",
      "7.45\n",
      "7.55\n",
      "-74.65\n"
     ]
    }
   ],
   "source": [
    "print(round(np.mean(X_test['bedrooms_squared']),2))\n",
    "\n",
    "print(round(np.mean(X_test['bed_bath_rooms']),2))\n",
    "\n",
    "print(round(np.mean(X_test['log_sqft_living']),2)) \n",
    "print(round(np.mean(X_test['lat_plus_long']),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uczenie wielu modeli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz poznamy wagi trzech (zagnieżdżonych) modeli do przewidywania cen domów. Pierwszy model będzie miał najmniej cech, drugi model doda jedną cechę, a trzeci doda jeszcze kilka:\n",
    "* Model 1: squarefeet, # bedrooms, # bathrooms, latitude & longitude\n",
    "* Model 2: + bedrooms\\*bathrooms\n",
    "* Model 3: + log squarefeet, bedrooms squared, i (bezsensowne) latitude + longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_features = ['sqft_living', 'bedrooms', 'bathrooms', 'lat', 'long']\n",
    "model_2_features = model_1_features + ['bed_bath_rooms']\n",
    "model_3_features = model_2_features + ['bedrooms_squared', 'log_sqft_living', 'lat_plus_long']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz, gdy mamy już cechy, poznaj wagi trzech różnych modeli do przewidywania docelowej = „ceny” za pomocą funkcji model_train i spójrz na wartość wag/współczynników:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcja szukająca współczynników modelu\n",
    "def model_train(X_train, Y_train):\n",
    "    pinw = np.linalg.pinv(X_train)\n",
    "    model = np.dot(pinw,Y_train)\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyucz 3 modele:\n",
    "model1 = model_train(X_train[model_1_features],y_train)\n",
    "model2 = model_train(X_train[model_2_features],y_train)\n",
    "model3 = model_train(X_train[model_3_features],y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.00159310e+02 -5.23689819e+04  4.58247068e+03  5.29238529e+05\n",
      "  2.05262847e+05]\n",
      "[ 2.92464746e+02 -1.21761358e+05 -1.09383881e+05  5.30036632e+05\n",
      "  2.03619080e+05  3.35897011e+04]\n",
      "[ 5.55032435e+02  1.34221113e+03  8.84250144e+04  3.03201909e+05\n",
      " -6.29628448e+04 -1.60202196e+04  8.18714827e+02 -6.45602857e+05\n",
      "  2.40239065e+05]\n"
     ]
    }
   ],
   "source": [
    "# Wyświetl wagi współczynników modelu:\n",
    "print(model1)\n",
    "print(model2)\n",
    "print(model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz: Jaki jest znak (dodatni lub ujemny) dla współczynnika/wagi dla „łazienek” w modelu 1?**\n",
    "\n",
    "**Quiz: Jaki jest znak (dodatni lub ujemny) dla współczynnika/wagi dla „łazienek” w modelu 2?**\n",
    "\n",
    "Zastanów się, co to znaczy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Znak współczynnika dla łazienek w modelu 1 jest dodatni;\n",
    "Znak współczynnika dla łazienek w modelu 2 jest ujemny.\n",
    "W drugiem modelu zawieramy zależność bed_bath_rooms, która uwzględnia w sobie łazienki, zależność ta ma stosunkowo duży współczynnik, a współczynnik przy bathrooms jest stosunkowo niewielki. Oznacza to, że dodanie nowej zależności tak bardzo premiuje łazienki, że ich wpływ na cenę musi być odpowiednio zrównoważony."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Porównywanie wielu modeli\n",
    "\n",
    "Teraz, gdy otrzymaliśmy trzy modele i wyodrębniliśmy wagi modeli, chcemy ocenić, który model jest najlepszy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Używając wcześniej opisanych funkcji obliczy SSE dla danych uczących dla każdego z trzech modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1082381909711009.6\n",
      "1065791753438920.2\n",
      "991825573399599.8\n"
     ]
    }
   ],
   "source": [
    "# Policz SSE na danych TRENINGOWYCH dla każdeg z 3 modeli i zapisz wartości:\n",
    "przykladowe_rss = policz_SSE(model1, X_train[model_1_features], y_train)\n",
    "print(przykladowe_rss)\n",
    "przykladowe_rss = policz_SSE(model2, X_train[model_2_features], y_train)\n",
    "print(przykladowe_rss) \n",
    "przykladowe_rss = policz_SSE(model3, X_train[model_3_features], y_train)\n",
    "print(przykladowe_rss) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz: Który model (1, 2 lub 3) ma najniższy poziom SSE na danych TRENINGOWYCH?** Czy tego się spodziewałeś/-łaś?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zgodnie z przewidywaniami, najmniejszy błąd ma model 3, czego się można było spodziewać, bo bierze pod uwagę najwięcej cech, które są ze sobą sensownie powiązane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz obliczyć SSE na danych TEST dla każdego z trzech modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233700269953888.62\n",
      "229575356886060.9\n",
      "221041949402646.5\n"
     ]
    }
   ],
   "source": [
    "# Teraz obliczyć SSE na danych TEST dla każdego z trzech modeli i zapisz wartości:\n",
    "przykladowe_rss = policz_SSE(model1, X_test[model_1_features], y_test)\n",
    "print(przykladowe_rss)\n",
    "przykladowe_rss = policz_SSE(model2, X_test[model_2_features], y_test)\n",
    "print(przykladowe_rss) \n",
    "przykladowe_rss = policz_SSE(model3, X_test[model_3_features], y_test)\n",
    "print(przykladowe_rss) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz: Który model (1, 2 lub 3) ma najniższy poziom SSE na danych TESTOWYCH?** Czy tego się spodziewałeś/-łaś? Pomyśl o cechach, które zostały dodane do każdego z modeli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zgodnie z przewidywaniami, najmniejszy błąd ma model 3, czego się można było spodziewać, bo bierze pod uwagę najwięcej cech, które są ze sobą sensownie powiązane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Policz pochodną"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przejdziemy teraz do obliczania pochodnej funkcji kosztu regresji. Przypomnij sobie, że funkcja kosztu jest sumą kwadratów różnic między punktami danych a przewidywanym wynikiem.\n",
    "\n",
    "Ponieważ pochodna sumy jest sumą pochodnych, możemy obliczyć pochodną dla pojedynczego punktu danych, a następnie zsumować na podstawie punktów danych. Możemy zapisać kwadratową różnicę między obserwowanym a przewidywanym wynikiem dla pojedynczego punktu w następujący sposób:\n",
    "\n",
    "(w[0]\\*[CONSTANT] + w[1]\\*[cecha_1] + ... + w[i] \\*[cecha_i] + ... +  w[k]\\*[cecha_k] - output)^2\n",
    "\n",
    "Gdzie mamy *k* cech i stałą. Tak więc pochodną w odniesieniu do wagi w[i] według reguły łańcucha jest:\n",
    "\n",
    "2\\*(w[0]\\*[CONSTANT] + w[1]\\*[cecha_1] + ... + w[i] \\*[cecha_i] + ... +  w[k]\\*[cecha_k] - output)\\* [cecha_i]\n",
    "\n",
    "Pojęcie w nawiasach to tylko błąd (różnica między prognozowaniem a wyjściem). Możemy więc ponownie napisać to jako:\n",
    "\n",
    "2\\*error\\*[cecha_i]\n",
    "\n",
    "Oznacza to, że pochodną wagi cechy *i* jest suma (ponad punkty danych) 2-krotności iloczynu błędu i samej cechy. W przypadku stałej jest to tylko dwukrotność sumy błędów!\n",
    "\n",
    "Przypomnijmy, że dwukrotność sumy iloczynu dwóch wektorów jest tylko dwukrotnością iloczynu dwóch wektorów. Dlatego pochodna wagi dla *cechy_i* jest tylko dwukrotnością iloczynu między wartościami *cechy_i* a bieżącymi błędami.\n",
    "\n",
    "Mając to na uwadze, należy napisać następującą funkcję liczącą pochodną, która oblicza pochodną współczynnika na podstawie wartości cechy (we wszystkich punktach danych) i błędów (we wszystkich punktach danych)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):\n",
    "    # Oblicz podwojony iloczyn cech i błędów, a następnie zwróć otrzymną wartość\n",
    "    derivative = 2*np.sum(errors)*feature\n",
    "    return(derivative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metoda spadku gradientu / gradientu prostego (Gradient Descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz napiszemy funkcję, która wykonuje spadek gradientu. Biorąc pod uwagę punkt początkowy, aktualizujemy bieżące wagi, przesuwając się w kierunku ujemnego gradientu. Przypomnijmy, że gradient jest kierunkiem *wzrostu*, a zatem gradient ujemny jest kierunkiem *spadku* i staramy się *zminimalizować* funkcję kosztu.\n",
    "\n",
    "Współczynnik, z jakim poruszamy się w kierunku gradientu ujemnego, nazywa się „rozmiarem kroku” - $\\alpha$. Zatrzymujemy się, gdy jesteśmy „wystarczająco blisko” do rozwiązania optymalnego. Definiujemy to, wymagając, aby wielkość (długość) wektora gradientu była mniejsza niż stała „tolerancja” - $\\epsilon$.\n",
    "\n",
    "Mając to na uwadze, wykonaj poniższą funkcję spadku gradientu poniżej, używając powyższej funkcji pochodnej. Dla każdego kroku zejścia gradientu aktualizujemy wagę każdej funkcji przed obliczeniem naszych kryteriów zatrzymania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt # wywołanie funkcji na wektorze [g[0], g[1], g[2]] daje sqrt(g[0]^2 + g[1]^2 + g[2]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_gradient_descent(feature_matrix, output, initial_weights, step_size, tolerance):\n",
    "    converged = False \n",
    "    weights = np.array(initial_weights) # miej pewność, że wagi są typu numpy array\n",
    "    while not converged:\n",
    "        # obliczyć prognozy na podstawie feature_matrix i wag za pomocą funkcji predict_output()\n",
    "        predictions = predict_output(weights, feature_matrix)\n",
    "\n",
    "        # wylicz błąd predykcji jako: predict_output - output\n",
    "        err = predictions-output\n",
    "\n",
    "        gradient_sum_squares = 0 # inicjuj sumę pierwiastków gradientów\n",
    "        # chociaż nie osiągnęliśmy jeszcze tolerancji, zaktualizuj wagę każdej funkcji\n",
    "        for i in range(len(weights)): # zapętlenie każdej wagi\n",
    "            # Przypomnij sobie, że feature_matrix [:, i] to kolumna cech powiązana z wagami[i]\n",
    "            # obliczyć pochodną dla wagi[i]:\n",
    "            derivative=feature_derivative(err, weights[i])\n",
    "            \n",
    "            # dodaj kwadrat wartości pochodnej do sumy kwadratów gradientów (ocena zbieżności)\n",
    "            gradient_sum_squares+=derivative*derivative\n",
    "\n",
    "            # odejmij wielkość kroku pomnożoną przez pochodną od bieżącej wagi\n",
    "            weights[i]-=step_size*derivative\n",
    "            \n",
    "        # oblicz pierwiastek kwadratowy z sumy gradientów kwadratów, aby uzyskać wielkość gradientu:\n",
    "        gradient_magnitude = sqrt(gradient_sum_squares)\n",
    "        if gradient_magnitude < tolerance:\n",
    "            converged = True\n",
    "    return(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kilka rzeczy, na które należy zwrócić uwagę, zanim zaczniemy korzystać z metody spadku gradientu. Ponieważ gradient jest sumą wszystkich punktów danych i obejmuje iloczyn błędu i wartości cechy, sam gradient będzie bardzo duży, ponieważ cechy są duże (stopy kwadratowe), a wynik jest duży (ceny). Tak więc, chociaż można oczekiwać, że „tolerancja” będzie niewielka, mała jest jedynie zależna od wielkości cechy.\n",
    "\n",
    "Z podobnych powodów rozmiar kroku będzie znacznie mniejszy niż można się spodziewać, ale dzieje się tak, ponieważ gradient ma tak duże wartości."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uruchamianie spadku gradientu jako prostej regresji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chociaż metoda spadku gradientu jest zaprojektowane dla regresji wielorakiej, ponieważ stała jest teraz funkcją, możemy użyć funkcji spadku gradientu do oszacowania parametrów prostej regresji na \"squarefeet\". Następująca komórka ustawia funkcję parametr_macierz, wynik, wagi początkowe i rozmiar kroku dla pierwszego modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def get_numpy_data(train_data, simple_features, my_output):\n",
    "    output = np.array(train_data[my_output])\n",
    "    simple_feature_matrix = np.array(train_data[simple_features])\n",
    "    return simple_feature_matrix, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test spadku gradientów\n",
    "simple_features = ['sqft_living']\n",
    "my_output = 'price'\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "(simple_feature_matrix, output) = get_numpy_data(train_data, simple_features, my_output)\n",
    "initial_weights = np.array([1.])\n",
    "step_size = 7e-12\n",
    "tolerance = 2.5e7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Następnie uruchom gradient z powyższymi parametrami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czas wykonania: 0.005425214767456055 sekund\n",
      "[260.78]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "w = regression_gradient_descent(simple_feature_matrix, output, initial_weights, step_size, tolerance)\n",
    "end = time.time()\n",
    "\n",
    "elapsed = end - start\n",
    "print(f\"Czas wykonania: {elapsed} sekund\")\n",
    "\n",
    "print(np.round(w,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porównaj wagi do tych uzyskanych przy pomocy pseudoodwrotności?\n",
    "\n",
    "**Pytanie quizu: Jaka jest waga sqft_living - drugi element „simple_weights” (w zaokrągleniu do 1 miejsca po przecinku)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[264.6]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(np.linalg.pinv(simple_feature_matrix).dot(output),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obie wagi są do siebie niesamowicie zbliżone; ich różnica jest na poziomie niecałych 2%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zobacz jak się zachowuje metoda gradientowa po przeskalowaniu wartości cech:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_train = X_train[simple_features]\n",
    "X_train_norm = (X_train-X_train.min())/(X_train.max()-X_train.min())\n",
    "\n",
    "train_data = pd.concat([X_train_norm, y_train], axis=1)\n",
    "(simple_feature_matrix, output) = get_numpy_data(train_data, simple_features, my_output)\n",
    "initial_weights = np.array([1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czas wykonania: 0.043436527252197266 sekund\n",
      "[260.78]\n"
     ]
    }
   ],
   "source": [
    "step_size = 7e-13\n",
    "\n",
    "start = time.time()\n",
    "w = regression_gradient_descent(simple_feature_matrix, output, initial_weights, step_size, tolerance)\n",
    "end = time.time()\n",
    "\n",
    "elapsed = end - start\n",
    "print(f\"Czas wykonania: {elapsed} sekund\")\n",
    "\n",
    "print(np.round(w,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać powyżej, otrzymany współczynnik jest wielokrtonie większy od wcześniej otrzymanego, co jest zgodne ze spodziewaniami. Dodatkowo, warto zauważyć, że bardzo istotna jest wielkość pojedynczego kroku - dla kroku zbyt dużego program nigdy nie skończy działania. Przykładem takiego zbyt dużego kroku jest 7e-12. Dla mniejszego kroku, program będzie się wykonywał statystycznie dłużej niż dla metody gradientowej bez przeskalowania."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
