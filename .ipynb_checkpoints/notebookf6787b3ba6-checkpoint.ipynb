{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10092472,"sourceType":"datasetVersion","datasetId":6223527},{"sourceId":10092494,"sourceType":"datasetVersion","datasetId":6223546}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import math \nimport matplotlib.pyplot as plt \nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.datasets import make_regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import mean_squared_error\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dtype_dict = {'Title':str, 'Geek Rating':float, 'Avg rating':float, 'Num of voters':int, 'Price':float, 'Year':str, 'Complexity':float, 'Min players':float, 'Max players':float, 'Min time':float, 'Max time':float, 'Age':float, 'Type 1':str, 'Type 2':str}\ndata = pd.read_csv('/kaggle/input/danefajne/bg_info.csv', dtype=dtype_dict)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data['Year'] = pd.to_numeric(data['Year'], errors='coerce')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 1. Analiza stopnia wypełnienia danych","metadata":{}},{"cell_type":"code","source":"print(\"Liczba danych: \" + str(data.shape[0]))\nprint(\"Liczba cech: \" + str(data.shape[1]))\ndata.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"non_null_ratios = data.notnull().sum() / data.shape[0]\n\nnum_columns = 2\nnum_rows = (len(data.columns) + num_columns - 1) // num_columns \n\nfig, axes = plt.subplots(num_rows, num_columns, figsize=(12, num_rows * 5))\naxes = axes.flatten() \n\nfor i, column in enumerate(data.columns):\n    non_null_count = non_null_ratios[column]\n    null_count = 1 - non_null_count\n    counts = [non_null_count, null_count]\n    labels = ['Non-Null', 'Null']\n    \n    axes[i].pie(counts, labels=labels, autopct='%1.1f%%', startangle=90)\n    axes[i].set_title(f\"{column}\")\n    \nfor j in range(len(data.columns), len(axes)):\n    fig.delaxes(axes[j])\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Zbiór składa sie z 25339 gier opisanych przez 14 cech, wliczając tytuł. Wszystkie gry mają w pełni uzupełnioną zmienną objaśnianą \"Num of voters\". W pełni uzupełnione też są kolumny: \"Geek Rating\", \"Avg rating\", \"Complexity\". Niewielkie braki znajdują się w kolumnach: \"Age\", \"Max time\", \"Min time\", \"Max players\" i \"Min players\". Duże braki znajdują sie w kolumnie \"Price\" oraz w kolumnach \"Type 1\" i Type 2\", które opisują kategorie gry.","metadata":{}},{"cell_type":"code","source":"rows_with_condition = data[(data['Type 1'].isnull()) & (data['Type 2'].notnull())]\n\nprint(len(rows_with_condition))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Do dalszej analizy zbioru zdecydowaliśmy się na odrzucenie cechy \"price\" z powodu dużych braków. Ponadto dla uproszeczenia modelu odrzuciliśmy ceche \"Type 2\" zakładając, że gdy gra ma dwie przypisane kategorie to \"Type 1\" zawiera tą ważniejszą. Po odrzuceniu tych dwóch cech odrzuciliśmy wiersze zawierające braki, ignorując jedynie braki w kolumnie \"Type 1\".","metadata":{}},{"cell_type":"code","source":"data = data.drop(columns = ['Type 2', 'Price'])\ndata = data.loc[data.drop(columns=['Type 1']).notnull().all(axis=1)] \n\ndata.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Zbadanie ich zakresów i stopnia zmienności","metadata":{}},{"cell_type":"code","source":"data.describe()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Jak widać na powyższym opisie, wiele cech charakteryzuje się dośc dużą rozpiętością zmienny, zwłaszcza tych o największej wartości. Cechą, która najbardziej się wyróżnia jest 'Max time' - trzeci kwartyl tej cechy stanowi zaledwie promil jej maksymalnej wartości. Innymi cechami, które mają niesamowicie duży rozrzut są 'Min time', 'Max players' oraz 'Num of voters'. Największy zakres ma 'Num of voters'.","metadata":{}},{"cell_type":"code","source":"numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n\n# Generowanie osobnych wykresów dla każdej zmiennej\nfor col in numeric_columns:\n    # Box Plot\n    plt.figure(figsize=(8, 4))\n    sns.boxplot(x=data[col])\n    plt.title(f'Box Plot for {col}')\n    plt.show()\n\n    # Violin Plot\n    plt.figure(figsize=(8, 4))\n    sns.violinplot(x=data[col], inner='quartile')\n    plt.title(f'Violin Plot for {col}')\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Funkcja na odrzucenie skrajnych wartości\ndef remove_outliers_std(df, column, n_std=3):\n    mean = df[column].mean()\n    std_dev = df[column].std()\n    return df[(df[column] >= mean - n_std * std_dev) & (df[column] <= mean + n_std * std_dev)]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Analiza relacji między zmiennymi","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nnumeric_df = data.select_dtypes(include=['float64', 'int64'])\ncorrelation_matrix = numeric_df.corr()\ncorrelation_sums = correlation_matrix.abs().sum() - 1\ncorrelation_sums = correlation_sums.sort_values(ascending=False)\n\nprint(\"Suma wartości bezwzględnych korelacji dla każdej cechy:\")\nprint(correlation_sums)\nsns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Jak widać powyżej, najbardziej skorelowanymi z sobą cechami są 'Geek Rating' oraz 'Num of voters' z korelacją 0.65. Innymi korelacjami, które warto wymienić, są 'Avg rating' i 'Geek Rating', 'Complexity' i 'Avg Rating', 'Min time' i 'Max time', 'Complexity' i 'Age'. Najmniej skorelowanymi cechami są 'Num of voters' oraz 'Price', 'Max players', 'Min time', 'Max time', a także 'Geek rating' i 'Min time', 'Min players' i 'Max time', 'Max players' i 'Age'. Cechą, która ma największą sumę wartości bezwględnych korelacji, jest 'Complexity'; tą, która ma najmniejszą, jest 'Max players'.","metadata":{}},{"cell_type":"markdown","source":"# 4. Analiza cech","metadata":{}},{"cell_type":"code","source":"\n\nfrom math import log, sqrt\ndata['Geek_square'] = data['Geek Rating']*data['Geek Rating']\ndata['Complexity_square'] = data['Complexity']*data['Complexity']\ndata['Complexity_Geek'] = data['Complexity']*data['Geek Rating']\ndata['Rating_sqrt'] = data['Avg rating'].apply(sqrt)\ndata['Rating_Geek'] = data['Avg rating']*data['Geek Rating']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.describe()\ndata.info()\nprint(data['Type 1'].unique())\ncategories = ['Strategy', 'Thematic', 'Family', 'Customizable', 'Abstract',\n              'Party', 'Wargames', \"Children's\", np.nan]\n\ndata['Category'] = data['Type 1'].fillna('Unknown')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\ndata['Year'] = pd.to_numeric(data['Year'], errors='coerce')  # Handle potential invalid values\ndata = data[data['Year'] >= 1900]\ndata = data[data['Num of voters'] <= 100000]\nlabel_encoder = LabelEncoder()\ndata = pd.get_dummies(data, columns=['Category'], prefix='Category')\ndata.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.describe()\ndata.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = data.drop(columns = ['Num of voters', 'Title', 'Type 1', 'Type 2', 'Price','Category_Encoded'])\ny = data['Num of voters']\nX = X.dropna()\ny = y.loc[X.index]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\nprint(len(X))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nfeatures = ['Category_Abstract', \"Category_Children's\", 'Category_Customizable', 'Category_Family', 'Category_Wargames','Category_Unknown','Category_Thematic','Category_Strategy','Category_Party'\n            ,'Geek Rating','Year', 'Avg rating',  'Complexity', 'Min players', \n            'Max players', 'Min time', 'Max time', 'Age', 'Geek_square', 'Complexity_square', 'Complexity_Geek', 'Rating_sqrt', 'Rating_Geek', 'Category_Encoded']\n\nselected_features = []\nremaining_features = features.copy()\ntest_r2_scores = []\nfeature_sets = []\n\n\nlr = LinearRegression()\n\nwhile remaining_features:\n    scores = []\n    for feature in remaining_features:\n        # Aktualne cechy\n        current_features = selected_features + [feature]\n\n        # Dane z wybranymi cechami\n        X2 = X_train[current_features]\n        y2 = y_train\n\n        # Obliczanie współczynnika determinacji R^2\n        r2_scores = cross_val_score(lr, X2, y2, cv=5, scoring='r2')\n        mean_r2 = np.mean(r2_scores)\n        scores.append(mean_r2)\n\n    # Wybór najlepszej cechy\n    max_r2 = max(scores)\n    best_feature = remaining_features[scores.index(max_r2)]\n\n    selected_features.append(best_feature)\n    remaining_features.remove(best_feature)\n    test_r2_scores.append(max_r2)\n    feature_sets.append(selected_features.copy())\n\n# Wyświetlenie wyników\nfor i, (features_set, r2) in enumerate(zip(feature_sets, test_r2_scores)):\n    print(f\"{i+1} cech: {features_set}, R^2 testowy: {r2:.4f}\")\n\n\"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}